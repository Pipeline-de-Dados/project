{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBNYx1Tbb6xp"
      },
      "source": [
        "# Instala√ß√£o das Bibliotecas Necess√°rias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dWzckKqCGe7y",
        "outputId": "1a590072-5e6d-4300-e3d3-cf1316433516"
      },
      "outputs": [],
      "source": [
        "!pip install PyDrive google-api-python-client google-auth google-auth-oauthlib google-cloud-storage requests pyjwt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZdIxvqQWVQS"
      },
      "source": [
        "# Realiza√ß√£o de importa√ß√µes necess√°rias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPEY6EsIb4xA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import unicodedata\n",
        "import requests\n",
        "import json\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "\n",
        "from google.oauth2.service_account import Credentials\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.cloud.exceptions import NotFound\n",
        "from googleapiclient.discovery import build\n",
        "from google.cloud import storage, bigquery\n",
        "from google.colab import files, auth\n",
        "from pandas_gbq import to_gbq\n",
        "from datetime import date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ1zCJ7_b8aU"
      },
      "source": [
        "# Recebimento de arquivos via Google Drive e envio para Google Cloud Storage (Bucket)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJzd2buxjNPg",
        "outputId": "0bc727f7-94b6-4462-fa8a-9a86f36f768c"
      },
      "outputs": [],
      "source": [
        "SERVICE_ACCOUNT_FILE = \"\" # Insira as credenciais da Conta de Servi√ßo\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_FILE\n",
        "SCOPES = [\n",
        "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "    \"https://www.googleapis.com/auth/documents\",\n",
        "    \"https://www.googleapis.com/auth/drive\"\n",
        "]\n",
        "FOLDER_ID = \"\" # Insira o ID da pasta que cont√©m os Dados\n",
        "BUCKET_NAME = \"\" # Insira o nome da Bucket no Google Cloud Storage\n",
        "\n",
        "# Autentica√ß√£o para o Google Drive e Google Cloud Storage\n",
        "credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "drive_service = build(\"drive\", \"v3\", credentials=credentials)\n",
        "storage_client = storage.Client.from_service_account_json(SERVICE_ACCOUNT_FILE)\n",
        "\n",
        "# Listar apenas os arquivos da pasta espec√≠fica\n",
        "print(\"\\nListando arquivos na pasta espec√≠fica:\")\n",
        "query = f\"'{FOLDER_ID}' in parents and trashed=false\"\n",
        "results = drive_service.files().list(\n",
        "    q=query,\n",
        "    pageSize=100,  # Ajuste conforme necess√°rio\n",
        "    orderBy=\"modifiedTime desc\",\n",
        "    fields=\"files(id, name, modifiedTime)\"\n",
        ").execute()\n",
        "files = results.get(\"files\", [])\n",
        "\n",
        "if not files:\n",
        "    print(\"‚ùå Nenhum arquivo encontrado na pasta especificada.\")\n",
        "else:\n",
        "    print(f\"Total de arquivos encontrados: {len(files)}\")\n",
        "\n",
        "    # Diret√≥rio local para salvar arquivos\n",
        "    local_folder = \"downloads_do_drive\"\n",
        "    os.makedirs(local_folder, exist_ok=True)\n",
        "\n",
        "    for file in files:\n",
        "        file_id = file[\"id\"]\n",
        "        file_name = file[\"name\"]\n",
        "        print(f\"\\nüåêBaixando arquivo: Nome: {file_name}, ID: {file_id}\")\n",
        "\n",
        "        # Baixar o arquivo do Google Drive\n",
        "        request = drive_service.files().get_media(fileId=file_id)\n",
        "        file_data = io.BytesIO()\n",
        "        downloader = MediaIoBaseDownload(file_data, request)\n",
        "        done = False\n",
        "        while not done:\n",
        "            status, done = downloader.next_chunk()\n",
        "            print(f\"Download {int(status.progress() * 100)}% ‚úÖ conclu√≠do para o arquivo '{file_name}'.\")\n",
        "        file_data.seek(0)\n",
        "\n",
        "        # Salvar o arquivo localmente\n",
        "        local_path = os.path.join(local_folder, file_name)\n",
        "        with open(local_path, \"wb\") as local_file:\n",
        "            local_file.write(file_data.read())\n",
        "        print(f\"Arquivo '{file_name}' salvo localmente em '{local_path}'.\")\n",
        "\n",
        "        # Resetar o ponteiro do stream para o in√≠cio antes do upload\n",
        "        file_data.seek(0)\n",
        "\n",
        "        # Enviar o arquivo para o bucket\n",
        "        pasta_bucket_envio = f\"dados_brutos/{file_name}\"\n",
        "        print(f\"\\nFazendo upload do arquivo '{file_name}' para o caminho {pasta_bucket_envio} no bucket '{BUCKET_NAME}'...\")\n",
        "        bucket = storage_client.bucket(BUCKET_NAME)\n",
        "        blob = bucket.blob(pasta_bucket_envio)\n",
        "        blob.upload_from_file(file_data, content_type='application/octet-stream')  # Ajuste o content_type se necess√°rio\n",
        "        print(f\"‚úÖ Arquivo '{file_name}' enviado com sucesso para o caminho '{pasta_bucket_envio}' no bucket '{BUCKET_NAME}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9UNjrunx5846"
      },
      "outputs": [],
      "source": [
        "# Configurar o ID da pasta de destino no Google Drive\n",
        "pasta_drive_backup = \"\" # Insira o ID da pasta de destino\n",
        "\n",
        "# Fun√ß√£o para mover os arquivos baixados para a pasta de destino no Google Drive\n",
        "def mover_arquivos_para_pasta_destino(files, pasta_drive_backup):\n",
        "    for file in files:\n",
        "        file_id = file[\"id\"]\n",
        "        file_name = file[\"name\"]\n",
        "        print(f\"\\nMovendo arquivo: Nome: {file_name}, ID: {file_id}\")\n",
        "\n",
        "        previous_parents = \",\".join([FOLDER_ID])  # Usa o ID da pasta de origem j√° definido\n",
        "        drive_service.files().update(\n",
        "            fileId=file_id,\n",
        "            addParents=pasta_drive_backup,\n",
        "            removeParents=previous_parents,\n",
        "            fields=\"id, parents\"\n",
        "        ).execute()\n",
        "\n",
        "        print(f\"Arquivo '{file_name}' movido para a pasta de destino com ID '{pasta_drive_backup}'.\")\n",
        "\n",
        "# Chamar a fun√ß√£o para mover os arquivos para a pasta de destino\n",
        "mover_arquivos_para_pasta_destino(files, pasta_drive_backup)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca7ukZm74t9l"
      },
      "source": [
        "# Excluir os arquivos locais ap√≥s o envio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "01kkNpkC1i10",
        "outputId": "49e2676c-4499-4337-f926-4f8c7d8bf4af"
      },
      "outputs": [],
      "source": [
        "for file_name in os.listdir(local_folder):  # Lista todos os arquivos na pasta local\n",
        "    local_path = os.path.join(local_folder, file_name)  # Caminho completo do arquivo\n",
        "    if os.path.isfile(local_path):  # Verifica se √© um arquivo (e n√£o um diret√≥rio)\n",
        "        os.remove(local_path)  # Exclui o arquivo\n",
        "        print(f\"Arquivo local '{file_name}' exclu√≠do.\")\n",
        "    else:\n",
        "        print(f\"'{file_name}' n√£o √© um arquivo, ignorado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCRkWwdo9e2D"
      },
      "source": [
        "# Fun√ß√µes para Normaliza√ß√£o e Envio de DataSets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV_rSzA0SIrV"
      },
      "outputs": [],
      "source": [
        "# TRATA OS ARQUIVOS (.sql)\n",
        "\n",
        "def sql_para_dataframe(blob):\n",
        "\n",
        "    # Converte um arquivo SQL contendo apenas comandos INSERT INTO em um DataFrame.\n",
        "    with blob.open(\"r\", encoding=\"utf-8\") as arquivo:\n",
        "         conteudo_sql = arquivo.read()\n",
        "\n",
        "    # Ajuste na regex para capturar corretamente o nome da tabela e os valores\n",
        "    padrao_insert = re.compile(r\"INSERT INTO `?([\\w\\s&]+)`?\\s*\\((.*?)\\)\\s*VALUES\\s*(.+);\", re.IGNORECASE)\n",
        "\n",
        "    correspondencias = padrao_insert.findall(conteudo_sql)\n",
        "    if not correspondencias:\n",
        "        print(f\"‚ö†Ô∏è Nenhum INSERT INTO encontrado em {blob.name}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    dados = []\n",
        "    colunas = []\n",
        "\n",
        "    for correspondencia in correspondencias:\n",
        "        nome_tabela, parte_colunas, parte_valores = correspondencia\n",
        "\n",
        "        # Remover espa√ßos extras e formatar colunas\n",
        "        if not colunas:\n",
        "            colunas = [col.strip().strip(\"`\") for col in parte_colunas.split(\",\")]\n",
        "\n",
        "        # Ajuste na separa√ß√£o dos valores para evitar que quebre errado por conta de v√≠rgulas internas\n",
        "        valores = re.findall(r\"\\((.*?)\\)\", parte_valores)\n",
        "\n",
        "        # Manter estrutura correta dos valores (respeitando strings com v√≠rgulas entre aspas)\n",
        "        for valor in valores:\n",
        "            valores_processados = [v.strip().strip(\"'\") for v in re.split(r\",(?=(?:[^']*'[^']*')*[^']*$)\", valor)]\n",
        "            dados.append(valores_processados)\n",
        "\n",
        "    dataframe = pd.DataFrame(dados, columns=colunas)\n",
        "\n",
        "    if dataframe.empty:\n",
        "        print(f\"‚ö†Ô∏è Nenhum dado extra√≠do corretamente de {blob.name}\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Dados extra√≠dos de {blob.name} corretamente!\")\n",
        "\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93DihcSNafsK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Procura colunas √∫nicas dentro do arquivo para gerar um nome padr√£o,\n",
        "Faz o upload do novo arquivo para a bucket de destino e\n",
        "Exclui o arquivo original\n",
        "\"\"\"\n",
        "def renomeia(df,blob, source_bucket_name,source_folder,dest_bucket_name, dest_folder):\n",
        "        client = storage.Client()\n",
        "        source_bucket = client.bucket(source_bucket_name)\n",
        "        dest_bucket = client.bucket(dest_bucket_name)\n",
        "        # Verifica se a coluna unica est√° presente\n",
        "        if \"nivel\" in df.columns and blob.name.endswith(\".json\"):\n",
        "            print(f\"Arquivo: {blob.name} √© ativos pj\")\n",
        "            new_file_name = \"ativos_pj\"\n",
        "        elif \"nivel\" in df.columns and blob.name.endswith(\".xlsx\"):\n",
        "            print(f\"Arquivo: {blob.name} √© ativos clt\")\n",
        "            new_file_name = \"ativos_clt\"\n",
        "        elif \"abertura_vaga\" in df.columns:\n",
        "            print(f\"Arquivo: {blob.name} √© abertura de  vagas\")\n",
        "            new_file_name = \"vagas_rs\"\n",
        "        elif \"Data de conclus√£o\" in df.columns:\n",
        "            print(f\"Arquivo: {blob.name} √© censo de diversidade\")\n",
        "            new_file_name = \"censo_diversidade\"\n",
        "        elif \"tipo_desligamento\" in df.columns:\n",
        "            print(f\"Arquivo: {blob.name} √© rela√ß√£o  de desligados\")\n",
        "            new_file_name = \"relacao_desligados\"\n",
        "        elif \"duracao\" in df.columns:\n",
        "            print(f\"Arquivo: {blob.name} √© Ferias Clt\")\n",
        "            new_file_name = \"ferias_clt\"\n",
        "        elif \"abertura vaga\" in df.columns:\n",
        "            print(f\"Arquivo: {blob.name} √© Vagas R&S\")\n",
        "            new_file_name = \"vagas_rs\"\n",
        "        elif \"Quant. dias\" in df.columns:\n",
        "            print(f\"Arquivo: {blob.name} √© f√©rias pj\")\n",
        "            new_file_name = \"ferias_pj\"\n",
        "        elif \"status\" in df.columns and blob.name.endswith(\".sql\"):\n",
        "            print(f\"‚ùåArquivo: {blob.name} √© Vagas R&S.sql\")\n",
        "            new_file_name = \"vagas_rs\"\n",
        "        else:\n",
        "            print(f\"‚ùå Arquivo: {blob.name} n√£o contem coluna unica\")\n",
        "            # Deletar o arquivo origem\n",
        "            try:\n",
        "                blob.delete()\n",
        "                print(f\"üÜóArquivo original {blob.name} exclu√≠do com sucesso da pasta dados_brutos.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao excluir o arquivo {blob.name} : {e}\")\n",
        "            return\n",
        "\n",
        "        caminho = f\"{dest_folder}/{new_file_name}.csv\"\n",
        "\n",
        "        # Salva o novo arquivo em mem√≥ria\n",
        "        print(f\"Arquivo: {blob.name} sendo salvo na memoria\")\n",
        "        output = io.StringIO()\n",
        "        df.to_csv(output, index=False)\n",
        "        output.seek(0)\n",
        "\n",
        "        # Faz o upload do novo arquivo para a bucket de destino\n",
        "        print(f\"‚è´Arquivo: {blob.name} sendo upado para dados_pre_processados\")\n",
        "        new_blob = dest_bucket.blob(caminho)\n",
        "        new_blob.upload_from_string(output.getvalue(), content_type=\"text/csv\")\n",
        "\n",
        "        # Verifica√ß√£o de sucesso do upload\n",
        "        if new_blob.exists():\n",
        "            print(f\"‚úÖ Novo arquivo criado com sucesso na pasta pre_preocessados: {new_file_name}\")\n",
        "            try:\n",
        "                blob.delete()\n",
        "                print(f\"üÜó Arquivo original {blob.name} exclu√≠do com sucesso da pasta dados_brutos.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao excluir o arquivo {blob.name} : {e}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Falha ao criar o novo arquivo para {blob.name}. O arquivo original n√£o foi exclu√≠do.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAQWksJQaj9G"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Lista todos os arquivos de uma bucket de origem.\n",
        "Tranforma o arquivo para csv baseado e sua extens√£o\n",
        "Chama a fun√ß√£o \"renomeia\" definida acima\n",
        "\"\"\"\n",
        "\n",
        "def processa_arquivos(source_bucket_name, source_folder, dest_bucket_name, dest_folder):\n",
        "    # Cria cliente do Google Cloud Storage\n",
        "    client = storage.Client()\n",
        "\n",
        "    # Referencia as buckets de origem e destino\n",
        "    source_bucket = client.bucket(source_bucket_name)\n",
        "    dest_bucket = client.bucket(dest_bucket_name)\n",
        "\n",
        "    # Lista todos os blobs (arquivos) na bucket de origem\n",
        "    blobs = source_bucket.list_blobs(prefix=source_folder)\n",
        "\n",
        "    # Trata cada arquivo conforme sua extens√£o\n",
        "    for blob in blobs:\n",
        "        if  blob.name.endswith(\".json\"):\n",
        "            ''' L√™ o formato jason, transforma em csv  e renomeia'''\n",
        "            print(f\"Arquivo: {blob.name} sendo precessado\")\n",
        "            file_data = blob.download_as_bytes()\n",
        "            data = json.loads(file_data.decode('utf-8'))\n",
        "\n",
        "            try:\n",
        "                # Tenta carregar o arquivo em um DataFrame\n",
        "                df = pd.DataFrame(data)\n",
        "                renomeia(df,blob, source_bucket_name,source_folder,dest_bucket_name, dest_folder)\n",
        "            except Exception as e:\n",
        "            # Captura qualquer erro e exibe a mensagem\n",
        "                print(f\"‚ùå Erro ao carregar o arquivo {blob.name} : {e}\")\n",
        "                try:\n",
        "                    blob.delete()\n",
        "                    print(f\"üÜóArquivo original {blob.name} exclu√≠do com sucesso da pasta dados_brutos.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erro ao excluir o arquivo {blob.name} : {e}\")\n",
        "\n",
        "        elif blob.name.endswith(\".txt\"):\n",
        "            #L√™ o formato  texto, transforma em csv  e renomeia\n",
        "            print(f\"Arquivo: {blob.name} sendo precessado\")\n",
        "            file_data = blob.download_as_bytes()\n",
        "            try:\n",
        "            # Tenta carregar o arquivo em um DataFrame\n",
        "                df = pd.read_csv(io.StringIO(file_data.decode('latin-1')), sep='\\t')\n",
        "                renomeia(df,blob, source_bucket_name,source_folder,dest_bucket_name, dest_folder)\n",
        "            except Exception as e:\n",
        "            # Captura qualquer erro e exibe a mensagem\n",
        "                print(f\"‚ùå Erro ao carregar o arquivo {blob.name} : {e}\")\n",
        "            try:\n",
        "                blob.delete()\n",
        "                print(f\"üÜó Arquivo original {blob.name} exclu√≠do com sucesso da pasta dados_brutos.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao excluir o arquivo {blob.name} : {e}\")\n",
        "\n",
        "        elif blob.name.endswith(\".xlsx\"):\n",
        "            # L√™ o formato  excel, transforma em csv  e renomeia\n",
        "            print(f\"Arquivo: {blob.name} sendo precessado\")\n",
        "            file_data = blob.download_as_bytes()\n",
        "\n",
        "            try:\n",
        "                # Tenta carregar o arquivo em um DataFrame\n",
        "                df = pd.read_excel(io.BytesIO(file_data))\n",
        "                renomeia(df,blob, source_bucket_name,source_folder,dest_bucket_name, dest_folder)\n",
        "            except Exception as e:\n",
        "                # Captura qualquer erro e exibe a mensagem\n",
        "                print(f\"‚ùå Erro ao carregar o arquivo {blob.name} : {e}\")\n",
        "                try:\n",
        "                    blob.delete()\n",
        "                    print(f\"üÜó Arquivo original {blob.name} exclu√≠do com sucesso da pasta dados_brutos.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erro ao excluir o arquivo {blob.name} : {e}\")\n",
        "\n",
        "        elif  blob.name.endswith(\".xls\"):\n",
        "            # L√™ o formato  excel, transforma em csv  e renomeia\n",
        "            print(f\"Arquivo: {blob.name} sendo precessado\")\n",
        "            file_data = blob.download_as_bytes()\n",
        "\n",
        "            try:\n",
        "                # Tenta carregar o arquivo em um DataFrame\n",
        "                df = pd.read_excel(io.BytesIO(file_data))\n",
        "                renomeia(df,blob, source_bucket_name,source_folder,dest_bucket_name, dest_folder)\n",
        "            except Exception as e:\n",
        "                # Captura qualquer erro e exibe a mensagem\n",
        "                print(f\"‚ùå Erro ao carregar o arquivo {blob.name} : {e}\")\n",
        "            try:\n",
        "                blob.delete()\n",
        "                print(f\"üÜó Arquivo original {blob.name} exclu√≠do com sucesso da pasta dados_brutos.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao excluir o arquivo {blob.name} : {e}\")\n",
        "\n",
        "        elif blob.name.endswith(\".gsheet\"):\n",
        "            # L√™ o formato  google sheets, transforma em csv  e renomeia\n",
        "            print(f\"Arquivo: {blob.name} sendo precessado\")\n",
        "\n",
        "            try:\n",
        "                # Tenta carregar o arquivo em um DataFrame\n",
        "                df = pd.read_excel(io.BytesIO(file_data))\n",
        "                renomeia(df,blob, source_bucket_name,source_folder,dest_bucket_name, dest_folder)\n",
        "            except Exception as e:\n",
        "                # Captura qualquer erro e exibe a mensagem\n",
        "                print(f\"‚ùå Erro ao carregar o arquivo {blob.name} : {e}\")\n",
        "            try:\n",
        "                blob.delete()\n",
        "                print(f\"üÜó Arquivo original {blob.name} exclu√≠do com sucesso da pasta dados_brutos.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao excluir o arquivo {blob.name} : {e}\")\n",
        "            df = pd.read_excel(io.BytesIO(file_data))\n",
        "\n",
        "        elif blob.name.endswith(\".csv\"):\n",
        "            # L√™ o formato  csv e renomeia\n",
        "            print(f\"Arquivo: {blob.name} sendo precessado\")\n",
        "            csv_data = blob.download_as_text()\n",
        "\n",
        "            try:\n",
        "                # Tenta carregar o arquivo em um DataFrame\n",
        "                df = pd.read_csv(io.StringIO(csv_data))\n",
        "                renomeia(df,blob, source_bucket_name,source_folder,dest_bucket_name, dest_folder)\n",
        "            except Exception as e:\n",
        "              # Captura qualquer erro e exibe a mensagem\n",
        "                print(f\"‚ùå Erro ao carregar o arquivo {blob.name} : {e}\")\n",
        "            try:\n",
        "                blob.delete()\n",
        "                print(f\"üÜó Arquivo original {blob.name} exclu√≠do com sucesso da pasta dados_brutos.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao excluir o arquivo {blob.name} : {e}\")\n",
        "\n",
        "        elif blob.name.endswith(\".sql\"):\n",
        "            # J√° foi processado por outro colab. Nada a fazer.\n",
        "            print(f\"Arquivo: {blob.name} sendo precessado\")\n",
        "\n",
        "            df = sql_para_dataframe(blob)\n",
        "\n",
        "            renomeia(df,blob, source_bucket_name,source_folder,dest_bucket_name, dest_folder)\n",
        "\n",
        "        elif blob.name == source_folder:\n",
        "            print(f\"üÜó Arquivo nulo encontrado: {blob.name}, ignorando processamento.\")\n",
        "\n",
        "        else:\n",
        "            print(f\"‚ùå Arquivo: {blob.name} n√£o est√° em um formato v√°lido\")\n",
        "            # Deletar o arquivo origem\n",
        "            try:\n",
        "                blob.delete()\n",
        "                print(f\"üÜó Arquivo original {blob.name} exclu√≠do com sucesso da pasta dados_brutos.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro ao excluir o arquivo {blob.name} : {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmamgcN4bFxl"
      },
      "source": [
        "# Execu√ß√£o das Fun√ß√µes de Tratamento e Envio para Bucket (dados_pre_processados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l201AeMyakts",
        "outputId": "0a58acd7-4a8e-4e9a-a246-b0ad08818c02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üÜó Arquivo nulo encontrado: dados_brutos/, ignorando processamento.\n"
          ]
        }
      ],
      "source": [
        "source_bucket_name = \"\" # Insira a Bucket de Origem dos arquivos\n",
        "source_folder = \"\" # Insira a Pasta de Origem dos arquivos\n",
        "dest_bucket_name = \"\" # Insira a Bucket de Destino dos arquivos\n",
        "dest_folder = \"\" # Insira a pasta de Destino dos arquivos\n",
        "processa_arquivos(source_bucket_name, source_folder, dest_bucket_name, dest_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyqUGHN0dvJx"
      },
      "source": [
        "# Tratamento Final e envio para BigQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGN8F-KWeJQJ"
      },
      "source": [
        "### Fun√ß√£o para o Tratamento Geral dos DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCkJpjlddviN"
      },
      "outputs": [],
      "source": [
        "def tratamento(dataframe):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o para tratar um DataFrame:\n",
        "    - Remove colunas espec√≠ficas.\n",
        "    - Verifica e trata valores nulos, vazios e duplicados.\n",
        "    - Trata valores string, aplicando formata√ß√£o apropriada.\n",
        "    - Ajusta os nomes das colunas para atender aos requisitos do BigQuery.\n",
        "    \"\"\"\n",
        "\n",
        "    excecoes = [\"de\", \"do\", \"da\", \"dos\", \"das\"]\n",
        "\n",
        "    # Remover colunas espec√≠ficas\n",
        "    try:\n",
        "        dataframe = dataframe.drop([\"mes referencia\", \"ano referencia\"], axis=1)\n",
        "        print(\"√äxito na exclus√£o das colunas.\")\n",
        "    except KeyError:\n",
        "        print(\"Uma ou mais colunas n√£o existem no DataFrame.\")\n",
        "\n",
        "    # Verificar valores nulos\n",
        "    valores_nulos = dataframe.isna()\n",
        "    contagem_nulos = valores_nulos.sum()\n",
        "    if contagem_nulos.sum() > 0:\n",
        "        print(\"Existem valores nulos no DataFrame:\")\n",
        "        print(contagem_nulos)\n",
        "        print(\"\\nDataFrame com valores nulos:\\n\", dataframe[valores_nulos.any(axis=1)].head())\n",
        "    else:\n",
        "        print(\"N√£o foram encontrados valores nulos no DataFrame.\")\n",
        "\n",
        "    # Verificar valores vazios\n",
        "    valores_vazios = dataframe == \"\"\n",
        "    contagem_vazios = valores_vazios.sum()\n",
        "    if contagem_vazios.sum() > 0:\n",
        "        print(\"Existem valores vazios no DataFrame:\")\n",
        "        print(contagem_vazios)\n",
        "        print(\"\\nDataFrame com valores vazios:\\n\", dataframe[valores_vazios.any(axis=1)].head())\n",
        "    else:\n",
        "        print(\"N√£o foram encontrados valores vazios no DataFrame.\")\n",
        "\n",
        "    # Remover duplicatas\n",
        "    duplicatas = dataframe.duplicated()\n",
        "    total_duplicatas = duplicatas.sum()\n",
        "    if total_duplicatas > 0:\n",
        "        print(f\"Foram encontradas {total_duplicatas} linhas duplicadas no DataFrame.\")\n",
        "        dataframe = dataframe.drop_duplicates().reset_index(drop=True)\n",
        "        print(\"As duplicatas foram removidas.\")\n",
        "    else:\n",
        "        print(\"N√£o foram encontradas duplicatas no DataFrame.\\n\")\n",
        "\n",
        "    # Tratar valores string\n",
        "    for coluna in dataframe.columns:\n",
        "        antes_strip = dataframe[coluna].copy()\n",
        "        if dataframe[coluna].dtype == \"object\":\n",
        "            dataframe.fillna(\"n√£o informado\", inplace=True)\n",
        "            dataframe[coluna] = dataframe[coluna].str.strip().apply(\n",
        "                lambda x: x.title() if isinstance(x, str) else x\n",
        "            )\n",
        "            dataframe[coluna] = dataframe[coluna].apply(\n",
        "                lambda x: \" \".join(\n",
        "                    [\n",
        "                        palavra.lower() if palavra.lower() in excecoes else palavra\n",
        "                        for palavra in x.split()\n",
        "                    ]\n",
        "                )\n",
        "                if isinstance(x, str)\n",
        "                else x\n",
        "            )\n",
        "            if not antes_strip.equals(dataframe[coluna]):\n",
        "                print(f\"A coluna '{coluna}' foi tratada para remover espa√ßos em branco extras e aplicar o t√≠tulo.\")\n",
        "            else:\n",
        "                print(f\"A coluna '{coluna}' n√£o continha espa√ßos em branco extras.\")\n",
        "        else:\n",
        "            print(f\"A coluna '{coluna}' n√£o √© do tipo string e n√£o foi tratada.\")\n",
        "\n",
        "    # Ajustar nomes das colunas\n",
        "    def ajustar_nome_coluna(coluna):\n",
        "\n",
        "        coluna = ''.join(\n",
        "            char for char in unicodedata.normalize('NFD', coluna)\n",
        "            if unicodedata.category(char) != 'Mn'\n",
        "        )\n",
        "        coluna = coluna.strip().lower()\n",
        "        coluna = re.sub(r\"[^\\w\\s]\", \"\", coluna)\n",
        "        coluna = coluna.replace(\" \", \"_\")\n",
        "        return coluna[:300]\n",
        "\n",
        "    colunas_originais = dataframe.columns.tolist()\n",
        "    colunas_tratadas = [ajustar_nome_coluna(col) for col in colunas_originais]\n",
        "\n",
        "    if colunas_tratadas != colunas_originais:\n",
        "        print(\"\\nNomes de colunas foram tratados:\")\n",
        "        print(f\"Antes: {colunas_originais}\")\n",
        "        print(f\"Depois: {colunas_tratadas}\")\n",
        "        dataframe.columns = colunas_tratadas\n",
        "\n",
        "    print(\"\\nInforma√ß√µes do DataFrame ap√≥s o tratamento:\")\n",
        "    dataframe.info()\n",
        "    print(\"\\nPr√©via do DataFrame tratado:\")\n",
        "    display(dataframe.head())\n",
        "\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVM5fP_LeLUv"
      },
      "source": [
        "## Fun√ß√£o para Leitura do Arquivo CSV da pasta de Origem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PKBb62leD09"
      },
      "outputs": [],
      "source": [
        "def read_csv_storage(arquivo):\n",
        "    bucket_name = \"\" # Insira o nome da Bucket de onde os arquivos ser√£o lidos\n",
        "    blob_name = f\"dados_pre_processados/{arquivo}.csv\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    with blob.open(\"r\") as f:\n",
        "      arquivo = pd.read_csv(f)\n",
        "\n",
        "    return arquivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YehCNf0wjWns"
      },
      "source": [
        "## Leitura e tratamento espec√≠ficos para cada DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2opgn2vjWns"
      },
      "source": [
        "### `ativos_clt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlvX_kA0jWns"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  df_ativos_clt = read_csv_storage(\"ativos_clt\")\n",
        "except:\n",
        "  print(\"Insira corretamente o nome do arquivo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TWpVwJ9KjWns",
        "outputId": "d1636b68-4502-494f-9727-e1645711bfef"
      },
      "outputs": [],
      "source": [
        "display(df_ativos_clt.head())\n",
        "df_ativos_clt.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS6LG_LUjWns"
      },
      "outputs": [],
      "source": [
        "df_ativos_clt[\"data admissao\"] = df_ativos_clt[\"data admissao\"].astype(str)\n",
        "df_ativos_clt[\"data admissao\"] = pd.to_datetime(df_ativos_clt[\"data admissao\"],format=\"%m/%d/%Y\")\n",
        "df_ativos_clt[\"data nascimento\"] = df_ativos_clt[\"data nascimento\"].astype(str)\n",
        "df_ativos_clt[\"data nascimento\"] = pd.to_datetime(df_ativos_clt[\"data nascimento\"],format=\"%m/%d/%Y\")\n",
        "df_ativos_clt = df_ativos_clt.rename(columns={\"cpf/id\" : \"id_funcionario\"})\n",
        "df_ativos_clt = df_ativos_clt.rename(columns={\"nivel\" : \"lider\"})\n",
        "df_ativos_clt.loc[df_ativos_clt[\"lider\"].str.contains(\"-\", na=False), \"lider\"] = \"n√£o\"\n",
        "df_ativos_clt.loc[df_ativos_clt[\"lider\"].str.contains(\"lideran√ßa\", na=False), \"lider\"] = \"sim\"\n",
        "df_ativos_clt[[\"area\",\"setor\"]] = df_ativos_clt[\"area\"].str.split(\" - \", n = 1, expand = True)\n",
        "df_ativos_clt[\"setor\"] = df_ativos_clt[\"setor\"].fillna(df_ativos_clt[\"area\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGUc-l8mjWnt",
        "outputId": "93897b48-2770-49f3-895d-c3af7e6900f9"
      },
      "outputs": [],
      "source": [
        "df_ativos_clt = tratamento(df_ativos_clt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRcENcGHjWnt"
      },
      "source": [
        "### `ativos_pj`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6805t1EbjWnt"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  df_ativos_pj = read_csv_storage(\"ativos_pj\")\n",
        "except:\n",
        "  print(\"Insira corretamente o nome do arquivo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmlEOxOJjWnt",
        "outputId": "79451d0d-9486-42ca-fdfd-c2d575cc52c6"
      },
      "outputs": [],
      "source": [
        "df_ativos_pj.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N45wA4zvjWnt"
      },
      "outputs": [],
      "source": [
        "df_ativos_pj[\"data admissao\"] = df_ativos_pj[\"data admissao\"].astype(str)\n",
        "df_ativos_pj[\"data admissao\"] = pd.to_datetime(df_ativos_pj[\"data admissao\"])\n",
        "df_ativos_pj[\"data nascimento\"] = df_ativos_pj[\"data nascimento\"].astype(str)\n",
        "df_ativos_pj[\"data nascimento\"] = pd.to_datetime(df_ativos_pj[\"data nascimento\"])\n",
        "df_ativos_pj = df_ativos_pj.rename(columns={\"cpf/id\" : \"id_funcionario\"})\n",
        "df_ativos_pj = df_ativos_pj.rename(columns={\"nivel\" : \"lider\"})\n",
        "df_ativos_pj.loc[df_ativos_pj[\"lider\"].str.contains(\"-\", na=False), \"lider\"] = \"n√£o\"\n",
        "df_ativos_pj.loc[df_ativos_pj[\"lider\"].str.contains(\"lideran√ßa\", na=False), \"lider\"] = \"sim\"\n",
        "df_ativos_pj[\"area\"] = df_ativos_pj[\"area\"].str.split(\" - \", n = 1, expand = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaFNof8AjWnt",
        "outputId": "8046d8a6-c783-400a-922b-af6fd03d67c6"
      },
      "outputs": [],
      "source": [
        "df_ativos_pj = tratamento(df_ativos_pj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdzjiW3SgpQ2"
      },
      "source": [
        "### `censo_diversidade`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlBcyp2Phe3a"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  df_censo = read_csv_storage(\"censo_diversidade\")\n",
        "except:\n",
        "  print(\"Insira corretamente o nome do arquivo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZQ-nS2niX-g",
        "outputId": "7e4edcb8-b58d-448c-d99a-49d373f0f42e"
      },
      "outputs": [],
      "source": [
        "display(df_censo.head())\n",
        "df_censo.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBcBSxpvw7qQ"
      },
      "outputs": [],
      "source": [
        "df_censo = df_censo.rename(\n",
        "    columns={\"De acordo com a Lei Geral de Prote√ß√£o de Dados Pessoais, voc√™ est√° consentindo com a coleta e uso de dados pessoais sens√≠veis seus, tais como ra√ßa, identidade de g√™nero, orienta√ß√£o sexual e outros, qu\" :\"Consentimento da coleta e uso de dados pessoais\",\n",
        "             \"True\" : \"Estou de acordo em responder\",\n",
        "             \"False\" : \"N√£o estou de acordo em responder\",\n",
        "             \"Qual sua idade?\" : \"idade\",\n",
        "             \"Qual seu nome social? O nome social √© o nome pelo qual uma pessoa √© conhecida e reconhecida socialmente, que pode ser diferente do seu nome de registro civil.\" :\"Nome social\",\"Qual posi√ß√£o voc√™ ocupa?\" : \"Posi√ß√£o\",\n",
        "             \"Coloque o nome do seu cargo\":\"Cargo\",\n",
        "             \"Qual seu estado de nascimento?\": \"Estado de nascimento\",\n",
        "             \"Qual estado voc√™ mora?\" : \"Estado que mora\",\n",
        "             \"Em qual regi√£o de S√£o Paulo voc√™ mora?\" : \"Regi√£o de S√£o Paulo que mora\",\n",
        "             \"Qual seu status de relacionamento afetivo?\" : \"Status de relacionamento afetivo\",\n",
        "             \"Existe alguma restri√ß√£o alimentar que devemos considerar ao planejar eventos ou reuni√µes? Se sim, justifique.\" :\"Restri√ß√£o alimentar\",\n",
        "             \"Voc√™ tem alguma sensibilidade a algum alimento ou subst√¢ncia? Se sim, justifique.\" :\"Sensibilidade a alimento ou subst√¢ncia\",\n",
        "             \"Voc√™ tem algum problema de sa√∫de/ alergias ou doen√ßa cr√¥nica que precisamos estar cientes? Se sim, justifique.\" :\"Problema de sa√∫de, alergias ou doen√ßa cr√¥nica\",\n",
        "             \"Como voc√™ se define em termos de identidade de g√™nero?\":\"Identidade de g√™nero\",\n",
        "             \"Como voc√™ se define em termos de sexo biologico\":\"Sexo biol√≥gico\",\n",
        "             \"Como voc√™ se define em termos de orienta√ß√£o sexual?\":\"Orienta√ß√£o sexual\",\n",
        "             \"Voc√™ se identifica como pessoa com defici√™ncia?\":\"Identifica√ß√£o com defici√™ncia\",\n",
        "             \"Etnia / ra√ßa / cor: Como voc√™ se identifica?\":\"Etnia, ra√ßa e cor\",\n",
        "             \"Qual o n√≠vel m√°ximo da sua educa√ß√£o formal?\" :\"N√≠vel m√°ximo de educa√ß√£o formal\",\n",
        "             \"Qual dom√≠nio com idiomas? Portugu√™s\":\"Dom√≠nio com idioma Portugu√™s\",\"Qual dom√≠nio com idiomas? Ingl√™s\":\"Dom√≠nio com idioma Ingl√™s\",\n",
        "             \"Qual dom√≠nio com idiomas? Espanhol\" :\"Dom√≠nio com idioma Espanhol\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_hhQEveKmR1T",
        "outputId": "78d2bfb7-f97d-49ac-b512-ea40b915da74"
      },
      "outputs": [],
      "source": [
        "df_censo[[\"Data de abertura\", \"Data de conclus√£o\"]] = df_censo[\n",
        "    [\"Data de abertura\", \"Data de conclus√£o\"]].apply(\n",
        "    pd.to_datetime, errors=\"coerce\"\n",
        ")\n",
        "df_censo.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "661pnhcdjVYJ",
        "outputId": "7d500865-7bb9-4124-df52-01a8ea7cc783"
      },
      "outputs": [],
      "source": [
        "df_censo = tratamento(df_censo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld7XoRor6RN9"
      },
      "outputs": [],
      "source": [
        "df_censo['email'] = df_censo['email'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoMHiXTcuHg0",
        "outputId": "acff5155-0df3-4a4e-a884-029b49124db0"
      },
      "outputs": [],
      "source": [
        "df_censo = df_censo.replace({\n",
        "    True: \"Sim\",\n",
        "    False: \"N√£o\",\n",
        "    \"Amarelo(A)\": \"Amarelo(a)\",\n",
        "    \"Negro(A)\": \"Negro(a)\",\n",
        "    \"Branco(A)\": \"Branco(a)\",\n",
        "    \"Pardo(A)\": \"Pardo(a)\",\n",
        "    \"Ind√≠gena\": \"Ind√≠gena\",\n",
        "    \"Male\": \"Masculino\",\n",
        "    \"Female\": \"Feminino\",\n",
        "    \"Bigender\": \"Big√™nero\",\n",
        "    \"Polygender\": \"Polig√™nero\",\n",
        "    \"Genderfluid\": \"G√™nero-fluido\",\n",
        "    \"Non-Binary\": \"N√£o-bin√°rio\",\n",
        "    \"Genderqueer\": \"G√™nero queer\"\n",
        "})\n",
        "\n",
        "# Exibir o DataFrame resultante\n",
        "display(df_censo.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZRY4OUiyZ6D",
        "outputId": "1a0fa802-ceda-49e4-a301-5933a6f83770"
      },
      "outputs": [],
      "source": [
        "display(df_censo.head(2))\n",
        "df_censo.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XWKldUGgoFP"
      },
      "source": [
        "### `ferias_clt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TTWICI-3ZWK"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  df_ferias_clt = read_csv_storage('ferias_clt')\n",
        "except:\n",
        "  print('Insira corretamente o nome do arquivo.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "-DUvP2Fz3jrq",
        "outputId": "ba2bdb5e-5d9a-420b-b279-c74d826501c0"
      },
      "outputs": [],
      "source": [
        "df_ferias_clt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "gXZk2k0WKXFf",
        "outputId": "ccfdc4cf-c666-46f2-f6d2-f8b51acd1751"
      },
      "outputs": [],
      "source": [
        "df_ferias_clt = df_ferias_clt.drop(columns=[\"Unnamed: 8\", \"Unnamed: 9\", \"Unnamed: 10\", \"Unnamed: 11\"])\n",
        "df_ferias_clt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "8PM3VsqzL4SW",
        "outputId": "078f628d-8415-4e28-804d-19a06b3aebb0"
      },
      "outputs": [],
      "source": [
        "df_ferias_clt[\"duracao\"] = df_ferias_clt[\"duracao\"].fillna(0)\n",
        "df_ferias_clt[\"duracao\"] = df_ferias_clt[\"duracao\"].round(0)\n",
        "df_ferias_clt[\"duracao\"] = df_ferias_clt[\"duracao\"].astype(int)\n",
        "\n",
        "display(df_ferias_clt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zjg4m3Hn4Gbk",
        "outputId": "a3aa1d70-7f13-4805-cff8-cacfd324dc94"
      },
      "outputs": [],
      "source": [
        "df_ferias_clt = tratamento(df_ferias_clt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnL0AwN05RJ_",
        "outputId": "3555b490-db9a-4ab5-c773-1387f84a3d9e"
      },
      "outputs": [],
      "source": [
        "if \"cpfid\" in df_ferias_clt.columns:\n",
        "    df_ferias_clt.rename(columns={\"cpfid\" : \"id_funcionario\"}, inplace=True)\n",
        "    print(\"Coluna 'cpfid' alterada para 'id_funcionario'.\")\n",
        "else:\n",
        "    print(\"N√£o existe coluna 'cpfid'.\")\n",
        "\n",
        "if \"id_funcionario\" in df_ferias_clt.columns:\n",
        "    df_ferias_clt['id_funcionario'] = df_ferias_clt['id_funcionario'].apply(lambda x: x if isinstance(x, str) and '-' in x else 'N√£o Informado')\n",
        "else:\n",
        "    None\n",
        "\n",
        "df_ferias_clt[\"data_inicio\"] = pd.to_datetime(\n",
        "    df_ferias_clt[\"data_inicio\"], errors=\"coerce\"\n",
        ")\n",
        "df_ferias_clt[\"data_termino\"] = pd.to_datetime(\n",
        "    df_ferias_clt[\"data_termino\"], errors=\"coerce\"\n",
        ")\n",
        "df_ferias_clt = df_ferias_clt.drop(index=258).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WTzm0WJYZCrj",
        "outputId": "9335a9fa-a8fb-4cd8-965f-41a69e0de1af"
      },
      "outputs": [],
      "source": [
        "df_ferias_clt.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWFCvPOjg7as"
      },
      "source": [
        "### `ferias_pj`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9BnL31vCz2J"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  df_ferias_pj = read_csv_storage('ferias_pj')\n",
        "except:\n",
        "  print('Insira corretamente o nome do arquivo.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "kcjRsKmcSwpE",
        "outputId": "a2ffc173-9b0d-4a15-c1c1-f32b6288f600"
      },
      "outputs": [],
      "source": [
        "df_ferias_pj.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SWuzrlHDC7A0",
        "outputId": "e3e93fbb-d059-4bb8-8fef-d257daee559b"
      },
      "outputs": [],
      "source": [
        "df_ferias_pj = tratamento(df_ferias_pj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cSVR__5Gw3h",
        "outputId": "b1850175-34eb-43a8-ee68-b8d121a2cbef"
      },
      "outputs": [],
      "source": [
        "df_ferias_pj = df_ferias_pj.rename(columns={\"quant_dias\": \"duracao\"})\n",
        "\n",
        "ordem_colunas = [\"data_solicitacao\", \"id_funcionario\", \"nome\", \"area\", \"data_inicio\", \"data_termino\", \"duracao\"]\n",
        "display(df_ferias_pj.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBe0fTfEE13O",
        "outputId": "e26ab0fd-1570-4189-9743-52a53561ff99"
      },
      "outputs": [],
      "source": [
        "if \"cpfid\" in df_ferias_pj.columns:\n",
        "    df_ferias_pj.rename(columns={\"cpfid\" : \"id_funcionario\"}, inplace=True)\n",
        "    print(\"Coluna 'cpfid' alterada para 'id_funcionario'.\")\n",
        "else:\n",
        "    print(\"N√£o existe coluna 'cpfid'.\")\n",
        "\n",
        "if \"id_funcionario\" in df_ferias_pj.columns:\n",
        "    df_ferias_pj['id_funcionario'] = df_ferias_pj['id_funcionario'].apply(lambda x: x if isinstance(x, str) and '-' in x else 'nao informado')\n",
        "else:\n",
        "    None\n",
        "\n",
        "df_ferias_pj[\"data_solicitacao\"] = pd.to_datetime(\n",
        "    df_ferias_pj[\"data_solicitacao\"], errors=\"coerce\"\n",
        ")\n",
        "df_ferias_pj[\"data_inicio\"] = pd.to_datetime(\n",
        "    df_ferias_pj[\"data_inicio\"], errors=\"coerce\"\n",
        ")\n",
        "df_ferias_pj[\"data_termino\"] = pd.to_datetime(\n",
        "    df_ferias_pj[\"data_termino\"], errors=\"coerce\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTX2Yb-cEZ9j",
        "outputId": "eff9474b-3e82-4230-b289-b5646d38055a"
      },
      "outputs": [],
      "source": [
        "df_ferias_pj.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9CADtfxXc_b"
      },
      "source": [
        "### `relacao_desligados`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "383q0SjgNsuc"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  df_relacao_desligados = read_csv_storage(\"relacao_desligados\")\n",
        "except:\n",
        "  print(\"Insira corretamente o nome do arquivo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a7FMktMaUUo",
        "outputId": "16405617-8d17-4877-8d19-017f9c86a56b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_relacao_desligados\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"mes referencia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"dezembro\",\n          \"setembro\",\n          \"junho\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ano referencia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2024,\n        \"max\": 2024,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_funcionario\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"753-95-4936\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nome\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"Avis Parlett\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tipo_desligamento\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Pedido de Demiss\\u00e3o\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_demissao\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 346,\n        \"samples\": [\n          \"2024-05-09\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cargo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"diretor de criacao\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_relacao_desligados"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-34517c72-feca-4b67-836b-34d4f3a27b1b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mes referencia</th>\n",
              "      <th>ano referencia</th>\n",
              "      <th>id_funcionario</th>\n",
              "      <th>nome</th>\n",
              "      <th>tipo_desligamento</th>\n",
              "      <th>data_demissao</th>\n",
              "      <th>cargo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>junho</td>\n",
              "      <td>2024</td>\n",
              "      <td>870-26-5986</td>\n",
              "      <td>Gerard Durran</td>\n",
              "      <td>Dispensa sem Justa Causa</td>\n",
              "      <td>2024-10-20</td>\n",
              "      <td>diretor de criacao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abril</td>\n",
              "      <td>2024</td>\n",
              "      <td>866-26-3608</td>\n",
              "      <td>Jard Dugget</td>\n",
              "      <td>Dispensa sem Justa Causa</td>\n",
              "      <td>2024-02-29</td>\n",
              "      <td>executivo de contas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>junho</td>\n",
              "      <td>2024</td>\n",
              "      <td>260-49-9909</td>\n",
              "      <td>Maure Ferguson</td>\n",
              "      <td>Pedido de Demiss√£o</td>\n",
              "      <td>2024-07-21</td>\n",
              "      <td>diretor de criacao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>julho</td>\n",
              "      <td>2024</td>\n",
              "      <td>330-13-2767</td>\n",
              "      <td>Marguerite Jupe</td>\n",
              "      <td>Dispensa sem Justa Causa</td>\n",
              "      <td>2024-09-21</td>\n",
              "      <td>coordenador de midia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>junho</td>\n",
              "      <td>2024</td>\n",
              "      <td>190-45-1192</td>\n",
              "      <td>Olivier Hurche</td>\n",
              "      <td>Pedido de Demiss√£o</td>\n",
              "      <td>2024-04-04</td>\n",
              "      <td>supervisor de planejamento</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34517c72-feca-4b67-836b-34d4f3a27b1b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34517c72-feca-4b67-836b-34d4f3a27b1b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34517c72-feca-4b67-836b-34d4f3a27b1b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8faa670e-5ce6-44a3-957e-a01324606836\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8faa670e-5ce6-44a3-957e-a01324606836')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8faa670e-5ce6-44a3-957e-a01324606836 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  mes referencia  ano referencia id_funcionario             nome  \\\n",
              "0          junho            2024    870-26-5986    Gerard Durran   \n",
              "1          abril            2024    866-26-3608      Jard Dugget   \n",
              "2          junho            2024    260-49-9909   Maure Ferguson   \n",
              "3          julho            2024    330-13-2767  Marguerite Jupe   \n",
              "4          junho            2024    190-45-1192   Olivier Hurche   \n",
              "\n",
              "          tipo_desligamento data_demissao                       cargo  \n",
              "0  Dispensa sem Justa Causa    2024-10-20          diretor de criacao  \n",
              "1  Dispensa sem Justa Causa    2024-02-29         executivo de contas  \n",
              "2        Pedido de Demiss√£o    2024-07-21          diretor de criacao  \n",
              "3  Dispensa sem Justa Causa    2024-09-21        coordenador de midia  \n",
              "4        Pedido de Demiss√£o    2024-04-04  supervisor de planejamento  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_relacao_desligados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELnrPKqhq-rg",
        "outputId": "11c74a14-aaad-48ba-d0b5-ffaed2c61d64"
      },
      "outputs": [],
      "source": [
        "df_relacao_desligados = tratamento(df_relacao_desligados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2WnRixZg-EX"
      },
      "source": [
        "### `vagas_rs`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4I2eg8OzW-t"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  df_vagas_rs = read_csv_storage(\"vagas_rs\")\n",
        "except:\n",
        "  print(\"Insira corretamente o nome do arquivo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWaDo8P90s6a",
        "outputId": "4e75f723-d3cc-46d6-a6fc-588659e6a95a"
      },
      "outputs": [],
      "source": [
        "df_vagas_rs = tratamento(df_vagas_rs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzbzN4pvz8og"
      },
      "outputs": [],
      "source": [
        "df_vagas_rs[\"abertura_vaga\"] = df_vagas_rs[\"abertura_vaga\"].astype(str)\n",
        "df_vagas_rs[\"abertura_vaga\"] = pd.to_datetime(df_vagas_rs[\"abertura_vaga\"], errors=\"coerce\")\n",
        "df_vagas_rs[\"fechamento_da_vaga\"] = df_vagas_rs[\"fechamento_da_vaga\"].astype(str)\n",
        "df_vagas_rs[\"fechamento_da_vaga\"] = pd.to_datetime(df_vagas_rs[\"fechamento_da_vaga\"], errors=\"coerce\")\n",
        "\n",
        "df_vagas_rs = df_vagas_rs.rename(columns={\n",
        "    \"substituicao__nova_vaga\":\"motivo_vaga\",\n",
        "    \"tipo_de_diversidade\":\"tipo_diversidade\",\n",
        "    \"identidade_de_genero\":\"identidade_genero\"\n",
        "})\n",
        "\n",
        "df_vagas_rs[\"vinculo\"] = df_vagas_rs[\"vinculo\"].replace({\n",
        "    \"Clt\":\"CLT\",\n",
        "    \"Pj\": \"PJ\"\n",
        "})\n",
        "\n",
        "df_vagas_rs[\"area\"] = df_vagas_rs[\"area\"].replace({\n",
        "    \"Bi\":\"BI\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBYJsuT21EP4",
        "outputId": "435e4477-d40b-4d0b-f549-06974d4cc05f"
      },
      "outputs": [],
      "source": [
        "display(df_vagas_rs.head())\n",
        "df_vagas_rs.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO_U42VYAENj"
      },
      "source": [
        "## Gera√ß√£o do Arquivo CSV, Download para a m√°quina e Envio para o Cloud Storage e BigQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMdmEsfcsGjX"
      },
      "source": [
        "### `ativos_clt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as_8_-lpyVa3",
        "outputId": "c1d69658-adfb-44ac-fc74-6920e1efa20a"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df_ativos_clt.to_csv(\"ativos_clt.csv\", index=False) # Substitua o nome do arquivo\n",
        "    print(\"Arquivo CSV 'ativos_clt.csv' gerado com sucesso!\\n\") # Substitua o nome do arquivo\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao gerar o arquivo CSV: {e}\\n\")\n",
        "\n",
        "try:\n",
        "    files.download(\"ativos_clt.csv\") # Substitua o nome do arquivo\n",
        "    print(\"Download do arquivo CSV realizado com sucesso!\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao fazer o download do arquivo CSV: {e}\\n\")\n",
        "\n",
        "def write_csv_storage(arquivo):\n",
        "    bucket_name = \"\" # Insira a Bucket de Destino dos arquivos\n",
        "    blob_name = f\"dados_tratados/{arquivo}.csv\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    blob.upload_from_filename(f\"{arquivo}.csv\")\n",
        "\n",
        "write_csv_storage(\"ativos_clt\")  # Substitua o nome do arquivo\n",
        "print(\"Arquivo enviado com sucesso para a a pasta 'dados_tratados'.\\n\")\n",
        "\n",
        "table_id = \"nome-do-projeto.nome-da-pasta.ativos_clt\" # Substitua o nome do arquivo\n",
        "\n",
        "try:\n",
        "    to_gbq(df_ativos_clt, table_id, project_id=project_id, if_exists=\"replace\")  # Substitua o nome do arquivo\n",
        "    print(\"\\n\\nEnvio para o BigQuery realizado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nErro ao enviar os dados para o BigQuery: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCwksudSsIFu"
      },
      "source": [
        "### `ativos_pj`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrDTrPgMCFrj",
        "outputId": "10375682-cfb0-44fc-b59f-54f9c57bb507"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df_ativos_pj.to_csv(\"ativos_pj.csv\", index=False) # Substitua o nome do arquivo\n",
        "    print(\"Arquivo CSV 'ativos_pj.csv' gerado com sucesso!\\n\") # Substitua o nome do arquivo\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao gerar o arquivo CSV: {e}\\n\")\n",
        "\n",
        "try:\n",
        "    files.download(\"ativos_pj.csv\") # Substitua o nome do arquivo\n",
        "    print(\"Download do arquivo CSV realizado com sucesso!\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao fazer o download do arquivo CSV: {e}\\n\")\n",
        "\n",
        "def write_csv_storage(arquivo):\n",
        "    bucket_name = \"\" # Insira a Bucket de Destino dos arquivos\n",
        "    blob_name = f\"dados_tratados/{arquivo}.csv\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    blob.upload_from_filename(f\"{arquivo}.csv\")\n",
        "\n",
        "write_csv_storage(\"ativos_pj\")  # Substitua o nome do arquivo\n",
        "print(\"Arquivo enviado com sucesso para a a pasta 'dados_tratados'.\\n\")\n",
        "\n",
        "table_id = \"nome-do-projeto.nome-da-pasta.ativos_pj\" # Substitua o nome do arquivo\n",
        "\n",
        "try:\n",
        "    to_gbq(df_ativos_pj, table_id, project_id=project_id, if_exists=\"replace\")  # Substitua o nome do arquivo\n",
        "    print(\"\\n\\nEnvio para o BigQuery realizado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nErro ao enviar os dados para o BigQuery: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zLHynWlsiqC"
      },
      "source": [
        "### `censo_diversidade`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SquvtGeks4CB",
        "outputId": "7c788d57-9fa4-4837-d1e9-8eec9d06c619"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df_censo.to_csv(\"censo_diversidade.csv\", index=False) # Substitua o nome do arquivo\n",
        "    print(\"Arquivo CSV 'censo_diversidade.csv' gerado com sucesso!\\n\") # Substitua o nome do arquivo\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao gerar o arquivo CSV: {e}\\n\")\n",
        "\n",
        "try:\n",
        "    files.download(\"censo_diversidade.csv\") # Substitua o nome do arquivo\n",
        "    print(\"Download do arquivo CSV realizado com sucesso!\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao fazer o download do arquivo CSV: {e}\\n\")\n",
        "\n",
        "def write_csv_storage(arquivo):\n",
        "    bucket_name = \"\" # Insira a Bucket de Destino dos arquivos\n",
        "    blob_name = f\"dados_tratados/{arquivo}.csv\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    blob.upload_from_filename(f\"{arquivo}.csv\")\n",
        "\n",
        "write_csv_storage(\"censo_diversidade\")  # Substitua o nome do arquivo\n",
        "print(\"Arquivo enviado com sucesso para a a pasta 'dados_tratados'.\\n\")\n",
        "\n",
        "table_id = \"nome-do-projeto.nome-da-pasta.censo_diversidade\" # Substitua o nome do arquivo\n",
        "\n",
        "try:\n",
        "    to_gbq(df_censo, table_id, project_id=project_id, if_exists=\"replace\")  # Substitua o nome do arquivo\n",
        "    print(\"\\n\\nEnvio para o BigQuery realizado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nErro ao enviar os dados para o BigQuery: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-GCUxfJsOio"
      },
      "source": [
        "### `ferias_clt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeCxJQTM-rZQ",
        "outputId": "0b4c4278-c06f-4850-e7f6-0c46f56abd2c"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df_ferias_clt.to_csv(\"ferias_clt.csv\", index=False) # Substitua o nome do arquivo\n",
        "    print(\"Arquivo CSV 'ferias_clt.csv' gerado com sucesso!\\n\") # Substitua o nome do arquivo\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao gerar o arquivo CSV: {e}\\n\")\n",
        "\n",
        "try:\n",
        "    files.download(\"ferias_clt.csv\") # Substitua o nome do arquivo\n",
        "    print(\"Download do arquivo CSV realizado com sucesso!\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao fazer o download do arquivo CSV: {e}\\n\")\n",
        "\n",
        "def write_csv_storage(arquivo):\n",
        "    bucket_name = \"\" # Insira a Bucket de Destino dos arquivos\n",
        "    blob_name = f\"dados_tratados/{arquivo}.csv\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    blob.upload_from_filename(f\"{arquivo}.csv\")\n",
        "\n",
        "write_csv_storage(\"ferias_clt\")  # Substitua o nome do arquivo\n",
        "print(\"Arquivo enviado com sucesso para a a pasta 'dados_tratados'.\\n\")\n",
        "\n",
        "table_id = \"nome-do-projeto.nome-da-pasta.ferias_clt\" # Substitua o nome do arquivo\n",
        "\n",
        "try:\n",
        "    to_gbq(df_ferias_clt, table_id, project_id=project_id, if_exists=\"replace\")  # Substitua o nome do arquivo\n",
        "    print(\"\\n\\nEnvio para o BigQuery realizado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nErro ao enviar os dados para o BigQuery: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdIb7c5YsVw_"
      },
      "source": [
        "### `ferias_pj`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Yh6QIzDKsab",
        "outputId": "3fd519c6-2262-41c4-edbe-e9097e1ed117"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df_ferias_pj.to_csv(\"ferias_pj.csv\", index=False) # Substitua o nome do arquivo\n",
        "    print(\"Arquivo CSV 'ferias_pj.csv' gerado com sucesso!\\n\") # Substitua o nome do arquivo\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao gerar o arquivo CSV: {e}\\n\")\n",
        "\n",
        "try:\n",
        "    files.download(\"ferias_pj.csv\") # Substitua o nome do arquivo\n",
        "    print(\"Download do arquivo CSV realizado com sucesso!\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao fazer o download do arquivo CSV: {e}\\n\")\n",
        "\n",
        "def write_csv_storage(arquivo):\n",
        "    bucket_name = \"\" # Insira a Bucket de Destino dos arquivos\n",
        "    blob_name = f\"dados_tratados/{arquivo}.csv\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    blob.upload_from_filename(f\"{arquivo}.csv\")\n",
        "\n",
        "write_csv_storage(\"ferias_pj\")  # Substitua o nome do arquivo\n",
        "print(\"Arquivo enviado com sucesso para a a pasta 'dados_tratados'.\\n\")\n",
        "\n",
        "table_id = \"nome-do-projeto.nome-da-pasta.ferias_pj\" # Substitua o nome do arquivo\n",
        "\n",
        "try:\n",
        "    to_gbq(df_ferias_pj, table_id, project_id=project_id, if_exists=\"replace\")  # Substitua o nome do arquivo\n",
        "    print(\"\\n\\nEnvio para o BigQuery realizado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nErro ao enviar os dados para o BigQuery: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqVnHUvPd8x0"
      },
      "source": [
        "### `relacao_desligados`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCE4bpbxa6DX",
        "outputId": "daa9fc9f-25f8-4a4d-dd58-889b9dd7ad9b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df_relacao_desligados.to_csv(\"relacao_desligados.csv\", index=False) # Substitua o nome do arquivo\n",
        "    print(\"Arquivo CSV 'relacao_desligados.csv' gerado com sucesso!\\n\") # Substitua o nome do arquivo\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao gerar o arquivo CSV: {e}\\n\")\n",
        "\n",
        "try:\n",
        "    files.download(\"relacao_desligados.csv\") # Substitua o nome do arquivo\n",
        "    print(\"Download do arquivo CSV realizado com sucesso!\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao fazer o download do arquivo CSV: {e}\\n\")\n",
        "\n",
        "def write_csv_storage(arquivo):\n",
        "    bucket_name = \"\" # Insira a Bucket de Destino dos arquivos\n",
        "    blob_name = f\"dados_tratados/{arquivo}.csv\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    blob.upload_from_filename(f\"{arquivo}.csv\")\n",
        "\n",
        "write_csv_storage(\"relacao_desligados\")  # Substitua o nome do arquivo\n",
        "print(\"Arquivo enviado com sucesso para a a pasta 'dados_tratados'.\\n\")\n",
        "\n",
        "table_id = \"nome-do-projeto.nome-da-pasta.relacao_desligados\" # Substitua o nome do arquivo\n",
        "\n",
        "try:\n",
        "    to_gbq(df_relacao_desligados, table_id, project_id=project_id, if_exists=\"replace\")  # Substitua o nome do arquivo\n",
        "    print(\"\\n\\nEnvio para o BigQuery realizado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nErro ao enviar os dados para o BigQuery: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LLfcbIGsc2l"
      },
      "source": [
        "### `vagas_rs`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw8jTNYj1asG",
        "outputId": "2b32ba86-0c78-40de-ecc9-16ae92c139df"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df_vagas_rs.to_csv(\"vagas_rs.csv\", index=False) # Substitua o nome do arquivo\n",
        "    print(\"Arquivo CSV 'vagas_rs.csv' gerado com sucesso!\\n\") # Substitua o nome do arquivo\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao gerar o arquivo CSV: {e}\\n\")\n",
        "\n",
        "try:\n",
        "    files.download(\"vagas_rs.csv\") # Substitua o nome do arquivo\n",
        "    print(\"Download do arquivo CSV realizado com sucesso!\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao fazer o download do arquivo CSV: {e}\\n\")\n",
        "\n",
        "def write_csv_storage(arquivo):\n",
        "    bucket_name = \"\" # Insira a Bucket de Destino dos arquivos\n",
        "    blob_name = f\"dados_tratados/{arquivo}.csv\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "\n",
        "    blob.upload_from_filename(f\"{arquivo}.csv\")\n",
        "\n",
        "write_csv_storage(\"vagas_rs\")  # Substitua o nome do arquivo\n",
        "print(\"Arquivo enviado com sucesso para a a pasta 'dados_tratados'.\\n\")\n",
        "\n",
        "table_id = \"nome-do-projeto.nome-da-pasta.vagas_rs\" # Substitua o nome do arquivo\n",
        "\n",
        "try:\n",
        "    to_gbq(df_vagas_rs, table_id, project_id=project_id, if_exists=\"replace\")  # Substitua o nome do arquivo\n",
        "    print(\"\\n\\nEnvio para o BigQuery realizado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nErro ao enviar os dados para o BigQuery: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KBNYx1Tbb6xp",
        "LZdIxvqQWVQS",
        "lQ1zCJ7_b8aU",
        "ca7ukZm74t9l",
        "Q2opgn2vjWns",
        "rRcENcGHjWnt",
        "NdzjiW3SgpQ2",
        "7XWKldUGgoFP",
        "xWFCvPOjg7as",
        "Q9CADtfxXc_b",
        "q2WnRixZg-EX"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
