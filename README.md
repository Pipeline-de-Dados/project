# ğŸ“Š Pipeline de Dados: do Zero ao Estrelato

Este projeto foi desenvolvido como parte do Bootcamp de AnÃ¡lise de Dados da SoulCode Academy, com o objetivo de aplicar tÃ©cnicas avanÃ§adas de anÃ¡lise de dados na resoluÃ§Ã£o de desafios reais do mercado. A iniciativa busca demonstrar como a automaÃ§Ã£o e a estruturaÃ§Ã£o de dados podem otimizar processos e gerar insights estratÃ©gicos para as empresas.

---

## ğŸ“Œ Sobre o Projeto

Criado para a DM9, o projeto foca na otimizaÃ§Ã£o dos processos do setor de Recursos Humanos, abordando desafios como a fragmentaÃ§Ã£o de dados e a execuÃ§Ã£o de tarefas manuais. Por meio de um pipeline eficiente utilizando Python, BigQuery e Power BI, a soluÃ§Ã£o melhora a confiabilidade das informaÃ§Ãµes, aumenta a escalabilidade e reduz custos operacionais. Os impactos incluem:

âœ… **Maior eficiÃªncia** e **reduÃ§Ã£o de custos operacionais**  
âœ… **Melhoria na confiabilidade e escalabilidade** dos processos  
âœ… **GeraÃ§Ã£o de insights estratÃ©gicos** para a empresa  

---

## ğŸ¢ Sobre a DM9

A [**DM9**](https://www.dm9.com.br/) Ã© uma renomada agÃªncia de publicidade brasileira, fundada em 1975 por **Duda MendonÃ§a**. Reconhecida por sua criatividade, foi a primeira agÃªncia do Brasil a conquistar o tÃ­tulo de "**AgÃªncia do Ano**" no **Cannes Lions**. Criou campanhas icÃ´nicas como **MamÃ­feros da Parmalat**, **Pipoca com GuaranÃ¡ Antarctica** e o comercial do **tetracampeonato do Brasil em 1994**. Em 1989, foi adquirida por **Nizan Guanaes** e **Guga Valente**, consolidando-se como uma das maiores referÃªncias do mercado publicitÃ¡rio.

---

## ğŸ›  Etapas do Projeto

O desenvolvimento deste projeto envolveu vÃ¡rias etapas para garantir um fluxo de dados eficiente, seguro e visualizÃ¡vel.

### 1ï¸âƒ£ Planejamento e DefiniÃ§Ã£o do Problema
ğŸ“Œ IdentificaÃ§Ã£o dos desafios enfrentados pelo setor de RH da DM9   
ğŸ“Œ CriaÃ§Ã£o do Diagrama de Fluxo de Dados (DFD) para planejar a estrutura do projeto   
ğŸ“Œ Levantamento de requisitos e definiÃ§Ã£o dos KPIs  
ğŸ“Œ Escolha das ferramentas e tecnologias

### 2ï¸âƒ£ Modelagem dos Dados

ğŸ“Œ CriaÃ§Ã£o do Diagrama Entidade-Relacionamento (DER) para organizar a estrutura dos dados   
ğŸ“Œ DefiniÃ§Ã£o dos relacionamentos entre as tabelas no BigQuery   
ğŸ“Œ NormalizaÃ§Ã£o dos dados para otimizar consultas

### 3ï¸âƒ£ ConstruÃ§Ã£o do Pipeline de Dados

ğŸ“Œ ExtraÃ§Ã£o dos dados de diversas fontes (JSONs, planilhas, banco de dados)     
ğŸ“Œ TransformaÃ§Ã£o e limpeza utilizando Python e pandas   
ğŸ“Œ Upload dos dados tratados para o Google Cloud Storage e envio ao BigQuery

### 4ï¸âƒ£ AnÃ¡lise e GeraÃ§Ã£o de Insights

ğŸ“Œ ExecuÃ§Ã£o de consultas no BigQuery para identificar padrÃµes   
ğŸ“Œ AplicaÃ§Ã£o de estatÃ­sticas descritivas e cruzamento de informaÃ§Ãµes relevantes     
ğŸ“Œ IdentificaÃ§Ã£o de tendÃªncias e possÃ­veis melhorias para o setor de RH

### 5ï¸âƒ£ VisualizaÃ§Ã£o dos Dados
ğŸ“Œ Desenvolvimento do dashboard no Power BI para facilitar a interpretaÃ§Ã£o dos dados    
ğŸ“Œ CriaÃ§Ã£o de grÃ¡ficos interativos e relatÃ³rios para os tomadores de decisÃ£o    
ğŸ“Œ Compartilhamento do dashboard para anÃ¡lise e feedback dos stakeholders

### 6ï¸âƒ£ DocumentaÃ§Ã£o e ApresentaÃ§Ã£o Final
ğŸ“Œ RedaÃ§Ã£o da documentaÃ§Ã£o do projeto, incluindo este README    
ğŸ“Œ CriaÃ§Ã£o dos slides da apresentaÃ§Ã£o no Figma  
ğŸ“Œ ValidaÃ§Ã£o dos resultados com a equipe e ajustes finais


---

## ğŸ›  Bibliotecas Utilizadas

O projeto utiliza diversas bibliotecas para **manipulaÃ§Ã£o de dados**, **integraÃ§Ã£o com APIs** e **armazenamento na nuvem**. Abaixo estÃ£o as principais bibliotecas e suas funÃ§Ãµes:

### ğŸ“‚ ManipulaÃ§Ã£o de Dados
- **`pandas`** â€“ Processamento e anÃ¡lise de dados estruturados.  
- **`unicodedata`** â€“ NormalizaÃ§Ã£o e tratamento de caracteres especiais.  
- **`re`** â€“ ManipulaÃ§Ã£o de expressÃµes regulares para limpeza e formataÃ§Ã£o de dados.  
- **`datetime`** â€“ ManipulaÃ§Ã£o de datas para organizaÃ§Ã£o e filtragem de informaÃ§Ãµes.  

### ğŸŒ IntegraÃ§Ã£o com APIs e RequisiÃ§Ãµes HTTP
- **`requests`** â€“ ComunicaÃ§Ã£o com APIs via HTTP.  
- **`json`** â€“ ManipulaÃ§Ã£o de dados em formato JSON.  
- **`io`** â€“ OperaÃ§Ãµes de entrada e saÃ­da de arquivos em memÃ³ria.  
- **`os`** â€“ InteraÃ§Ã£o com o sistema operacional.  

### ğŸ” AutenticaÃ§Ã£o e Acesso a ServiÃ§os do Google
- **`google.oauth2.service_account.Credentials`** â€“ AutenticaÃ§Ã£o via credenciais de conta de serviÃ§o.  
- **`googleapiclient.discovery.build`** â€“ ConexÃ£o com APIs do Google (ex: Drive, Sheets).  
- **`googleapiclient.http.MediaIoBaseDownload`** â€“ Download de arquivos via API do Google Drive.  
- **`google.cloud.storage`** â€“ ManipulaÃ§Ã£o de arquivos no Google Cloud Storage.  
- **`google.cloud.bigquery`** â€“ ConexÃ£o e interaÃ§Ã£o com o BigQuery.  
- **`google.cloud.exceptions.NotFound`** â€“ Tratamento de exceÃ§Ãµes ao acessar dados no Google Cloud.  
- **`pandas_gbq.to_gbq`** â€“ Envio de DataFrames para o BigQuery.  

### ğŸ— Google Colab
- **`google.colab.files`** â€“ Upload e download de arquivos no ambiente do Colab.  
- **`google.colab.auth`** â€“ AutenticaÃ§Ã£o no Google Colab.  

### ğŸ”§ Bibliotecas Instaladas via `pip`
AlÃ©m das bibliotecas mencionadas, tambÃ©m foram instaladas dependÃªncias externas para integraÃ§Ã£o com APIs do Google e autenticaÃ§Ã£o:

```bash
!pip install PyDrive google-api-python-client google-auth google-auth-oauthlib google-cloud-storage requests pyjwt
```

---

## â˜ï¸ Uso do Google Cloud
O Google Cloud desempenha um papel essencial na infraestrutura deste projeto, garantindo armazenamento escalÃ¡vel, processamento eficiente e anÃ¡lises rÃ¡pidas. Utilizamos os seguintes serviÃ§os:

### ğŸ”¹BigQuery
O BigQuery Ã© um data warehouse totalmente gerenciado que permite anÃ¡lises rÃ¡pidas em grandes volumes de dados. Neste projeto, ele Ã© utilizado para:     
âœ… Armazenar dados estruturados     
âœ… Executar consultas SQL otimizadas    
âœ… Gerar insights em tempo real

### ğŸ”¹Google Cloud Storage
O Google Cloud Storage permite o armazenamento seguro de arquivos brutos antes do processamento. Suas vantagens incluem:    
âœ… Alta disponibilidade e seguranÃ§a     
âœ… IntegraÃ§Ã£o com outras ferramentas do Google Cloud    
âœ… Escalabilidade para grandes volumes de dados

### ğŸ”¹APIs do Google Cloud
AlÃ©m do armazenamento e processamento, utilizamos APIs do Google Cloud para:

AutenticaÃ§Ã£o e autorizaÃ§Ã£o (Google OAuth e Service Accounts)    
InteraÃ§Ã£o com o Google Drive (importaÃ§Ã£o/exportaÃ§Ã£o de arquivos)    
IntegraÃ§Ã£o direta com BigQuery usando pandas_gbq


---

## ğŸ“‚ Estrutura do RepositÃ³rio
ğŸ“ `apresentacao/` â€“ Slides em PDF explicando o projeto  
ğŸ“ `dados/` â€“ Arquivos de entrada utilizados na anÃ¡lise  
ğŸ“ `diagramas/` â€“ Slides em PDF explicando o projeto  
ğŸ“ `notebooks/` â€“ Jupyter Notebooks com cÃ³digos Python  


---

## ğŸ† Resultados e Impacto

ğŸš€ **ReduÃ§Ã£o de tempo gasto** com anÃ¡lise manual de dados  
ğŸ“‰ **MinimizaÃ§Ã£o de erros humanos** na tomada de decisÃ£o  
ğŸ“Š **Aumento da confiabilidade e escalabilidade** das informaÃ§Ãµes  

> **Este projeto foi desenvolvido como parte do Bootcamp de AnÃ¡lise de Dados promovido pela SoulCode Academy em parceria com a Flora CosmÃ©ticos e Meio & Mensagem.**

---

## ğŸ‘¥ Equipe do Projeto

ğŸ‘¤ **[Ãlevy Bruno](https://www.github.com/alevybruno)**  
ğŸ‘¤ **[DionÃ­sio Ribeiro](https://www.github.com/dionisio2024)**  
ğŸ‘¤ **[Joshua Bertocchi](https://www.github.com/JoshuaBertocchi)**  
ğŸ‘¤ **[kleiton Santos](https://www.github.com/kleistsux)**  
ğŸ‘¤ **[Lorena Gutierrez](https://www.github.com/lorenavelina)**  
ğŸ‘¤ **[Lucas Aguiar](https://www.github.com/Lucas-335)**  
ğŸ‘¤ **[Matheus Vaz](https://www.github.com/matheusvazdata)**  
ğŸ‘¤ **[Nicolly Rodrigues](https://www.github.com/nicky89ck)**  


---

